rule all:
    input:
        expand(config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}.pdf", sampleSet = ['breedSample'], regionSet = ['all'])


rule create_gz_index:
    input:
        vcf="{file}"
    output:
        reheader_gz="{file}.reheader.gz",
        index="{file}.reheader.gz.csi",
        rename=temp("{file}rename_samples_vcf.txt"),
        reheader=temp("{file}.reheader")
    threads:
        config['resources']['threads']
    conda:
        config['envs']['phylogenetics']
    shell:
        '''
        rm -f {input.vcf}".gz" {input.vcf}".gz.csi"
        sample_name=`basename {input.vcf} "_rg_added_sorted_dedupped_removed.realigned.bam.filter.vcf"`
        echo "${{sample_name}}" > {output.rename}
        bcftools reheader -s {output.rename} --threads {threads} {input.vcf} | awk '{{ if($1 ~ /##/ || NF==10)print}}' > {output.reheader}
        bgzip --force --threads {threads} {output.reheader}
        bcftools index --threads {threads} {output.reheader_gz}
        echo "Compressed and indexed {input.vcf}"
        '''



# rule merge_vcfs:
#     input:
#         vcf=expand("{file}.reheader.gz", file=config['in']['vcffiles']),
#         index=expand("{file}.reheader.gz.csi", file=config['in']['vcffiles'])
#     output:
#         merged_vcf=config['out']['outdir']+"/all_merged_germline_variants.vcf.gz"
#     threads:
#         config['resources']['threads']
#     conda:
#         config['envs']['phylogenetics']
#     shell:
#         '''
#         bcftools merge --threads {threads} -Oz \
#             --force-samples --missing-to-ref \
#             -o {output.merged_vcf} \
#             {input.vcf}
#         '''

# rule filter_merged_vcf:
#     input:
#         merged_vcf=config['out']['outdir']+"/all_merged_germline_variants.vcf.gz"
#     output:
#         filtered_vcf=config['out']['outdir']+"/all_merged_germline_variants_SNP.vcf.gz"
#     threads:
#         config['resources']['threads']
#     conda:
#         config['envs']['phylogenetics']
#     shell:
#         '''
#         bcftools view --threads {threads} -Oz \
#             -f PASS --types snps \
#             -o {output.filtered_vcf} \
#             {input.merged_vcf}
#         '''

# sampleSet = ['breedSample', 'breedPlusMissingSample']
# rule create_sample_list:
#     input:
#         config['in']['metatable']
#     output:
#         breedSample=config['out']['outdir']+"/breedSample.list",
#         breedPlusMissing=config['out']['outdir']+"/breedPlusMissingSample.list"
#     params:
#         breeds = ['Shih Tzu','Schnauzer','Golden Retriever','Rottweiler','Greyhound','Maltese','Yorkshire Terrier','Boxer','Poodle','Cocker Spaniel']
#     run:
#         import csv
#         out1 = open(output['breedSample'], "w")
#         out2 = open(output['breedPlusMissing'], "w")

#         with open(input[0], 'r') as file:
#             reader = csv.reader(file, delimiter=',', quotechar='"')
#             header = next(reader)
#             breed_idx = header.index('Breed_info')
#             sample_idx = header.index('Sample_ID')
#             status_idx = header.index('Status')
#             qc_idx = header.index('Reason_to_exclude')
#             for row in reader:
#                 if 'Normal' in row[status_idx] and 'Pass QC' in row[qc_idx]:
#                     if row[breed_idx] in params['breeds']:
#                         out1.write(row[sample_idx]+"\n")
#                         out2.write(row[sample_idx]+"\n")
#                     elif "No breed provided" in row[breed_idx]:
#                         out2.write(row[sample_idx]+"\n")
        
#         out1.close()
#         out2.close()

rule subset_samples:
    input:
        filtered_vcf=config['out']['outdir']+"/all_merged_germline_variants_SNP.vcf.gz",
        breedSample=config['out']['outdir']+"/breedSample.list",
        breedPlusMissing=config['out']['outdir']+"/breedPlusMissingSample.list"
    output:
        breedSample_vcf=config['out']['outdir']+"/breedSample_all_merged_germline_variants_SNP.vcf.gz",
        breedSample_idx=config['out']['outdir']+"/breedSample_all_merged_germline_variants_SNP.vcf.gz.csi",
        breedPlusMissing_vcf=config['out']['outdir']+"/breedPlusMissingSample_all_merged_germline_variants_SNP.vcf.gz",
        breedPlusMissing_idx=config['out']['outdir']+"/breedPlusMissingSample_all_merged_germline_variants_SNP.vcf.gz.csi"
    threads:
        config['resources']['threads']
    conda:
        config['envs']['phylogenetics']
    shell:
        '''
        bcftools view --threads {threads} -O z \
            -S {input.breedSample} \
            --force-samples \
            -o {output.breedSample_vcf} \
            {input.filtered_vcf}
        bcftools index {output.breedSample_vcf}
        bcftools view --threads {threads} -O z \
            -S {input.breedPlusMissing} \
            --force-samples \
            -o {output.breedPlusMissing_vcf} \
            {input.filtered_vcf}
        bcftools index {output.breedPlusMissing_vcf}
        '''


rule prepare_breedSpecific_sites:
    input:
        config['in']['breedSpecific']
    output:
        config['out']['outdir']+"/breedSpecific_sites.tab"
    shell:
        '''
        awk 'BEGIN{{OFS="\\t"}} {{if ($2 !~ /Locus/) {{split($2,POS,":"); print POS[1],POS[2];}} }}' \
            {input} > {output}
        '''

# sampleSet = ['breedSample', 'breedPlusMissingSample']
# regionSet = ['breedSpecific', 'all' ,'genes']

rule subset_breedSpecific:
    input:
        vcf=config['out']['outdir']+"/{sampleSet}_all_merged_germline_variants_SNP.vcf.gz",
        idx=config['out']['outdir']+"/{sampleSet}_all_merged_germline_variants_SNP.vcf.gz.csi",
        sites=config['out']['outdir']+"/breedSpecific_sites.tab"
    output:
        vcf=config['out']['outdir']+"/{sampleSet}_breedSpecific_merged_germline_variants_SNP.vcf.gz",
        idx=config['out']['outdir']+"/{sampleSet}_breedSpecific_merged_germline_variants_SNP.vcf.gz.csi"
    threads:
        config['resources']['threads']
    conda:
        config['envs']['phylogenetics']
    shell:
        '''
        bcftools view --threads {threads} -O z \
            -R {input.sites} \
            --force-samples \
            -o {output.vcf} \
            {input.vcf}
        bcftools index {output.vcf}
        '''

rule create_depth_file_list:
    input:
        sampleSet=config['out']['outdir']+"/{sampleSet}.list",
        vcffilelist=config['in']['vcffilelist']
    output:
        depthfilelist=config['out']['outdir']+"/{sampleSet}_all_depth_file_list.txt"
    threads:
        1
    shell:
        '''
        # samples in order
        grep -f {input.sampleSet} {input.vcffilelist} |  awk 'NR==FNR {{ line[$1] = $0; next }} $1 in line {{ print line[$1] }}' - {input.sampleSet} | cut -f3 > {output.depthfilelist}
        '''

rule depth_position_list:
    input:
        depthfilelist=config['out']['outdir']+"/{sampleSet}_depth_file_list.txt"
    output:
        depthpositionlist=config['out']['outdir']+"/{sampleSet}_depth_position_list.txt",
        depthpositiontab=config['out']['outdir']+"/{sampleSet}_depth_position_list.tab"
    threads:
        1
    shell:
        '''
        # get depth position list from first depth file
        file=`head -1 {input.depthfilelist}`
        sed '1d' ${{file}} | cut -f1 > {output.depthpositionlist}
        awk 'BEGIN{{FS=":";OFS="\\t"}}{{print $1,$2}}' {output.depthpositionlist} > {output.depthpositiontab}
        '''

# sites in merged VCF are different from interval of DepthOfCoverage
rule subset_depth_sites:
    input:
        vcf=config['out']['outdir']+"/{sampleSet}_all_merged_germline_variants_SNP.vcf.gz",
        depthpositiontab=config['out']['outdir']+"/{sampleSet}_depth_position_list.tab"
    output:
        out_vcf=config['out']['outdir']+"/{sampleSet}_all_merged_germline_variants_SNP_depth.vcf.gz",
        # out_index=config['out']['outdir']+"/{sampleSet}_all_merged_germline_variants_SNP_depth.vcf.gz.csi"
    threads:
        config['resources']['threads']
    conda:
        config['envs']['phylogenetics']
    shell:
        '''
        bcftools view --threads {threads} -O z \
            -R {input.depthpositiontab} \
            -o {output.out_vcf} \
            {input.vcf}
        # bcftools index {output.out_vcf}
        '''


rule create_variant_list:
    input:
        vcf=config['out']['outdir']+"/{sampleSet}_all_merged_germline_variants_SNP_depth.vcf.gz",
    output:
        variantlist=config['out']['outdir']+"/{sampleSet}_all_depth_variant_list.txt"
    threads:
        1
    shell:
        '''
        # get varaint sites in order
        zcat {input.vcf} |\
            awk 'BEGIN{{OFS=":"}}/^[^#]/{{print $1,$2}}' > {output.variantlist}
        '''

rule create_depth_matrix:
    input:
        vcf=config['out']['outdir']+"/{sampleSet}_all_merged_germline_variants_SNP_depth.vcf.gz",
        variantlist=config['out']['outdir']+"/{sampleSet}_all_depth_variant_list.txt",
        depthfilelist=config['out']['outdir']+"/{sampleSet}_all_depth_file_list.txt"
    output:
        tmp_depth=temp(config['out']['outdir']+"/{sampleSet}_all_tmp_DepthofCoverage_CDS.txt"),
        tmp_leftalign=temp(config['out']['outdir']+"/{sampleSet}_all_tmp_DepthofCoverage_CDS_leftalign.txt"),
        depthmatrix=config['out']['outdir']+"/{sampleSet}_all_germline_depth_matrix_for_phylo.txt",
        tmp_matrix=temp(config['out']['outdir']+"/{sampleSet}_all_tmp.txt"),
        tmp_variantlist=temp(config['out']['outdir']+"/{sampleSet}_all_depth_variant_list_tmp.txt")
    threads:
        1
    shell:
        '''
        # select variant sites for depth info in order
        awk '{{print $0","}}' {input.variantlist} > {output.tmp_variantlist}
        while read file; do
            # sort depth file to fit the variant sites order, fill missing sites
            awk 'BEGIN{{OFS=","}}{{print $1,$2}}' ${{file}} | grep -f {output.tmp_variantlist} | cut -f1,2 > {output.tmp_depth}
            join -a1 -e- -t "," -j 1 -o 0 2.2 <(sort {input.variantlist}) <(sort {output.tmp_depth}) | tr : , | sort -t, -k1.4,1V -k2,2n | sed 's/,/:/' > {output.tmp_leftalign}
            if [[ ! -e {output.depthmatrix} ]]; then
                cp {input.variantlist} {output.depthmatrix}
                join -t "," -j 1 {output.depthmatrix} {output.tmp_leftalign} > {output.tmp_matrix}
                # paste -d, {output.depthmatrix} {output.tmp_leftalign} > {output.tmp_matrix}
                cp {output.tmp_matrix} {output.depthmatrix}
            else
                join -t "," -j 1 {output.depthmatrix} {output.tmp_leftalign} > {output.tmp_matrix}
                cp {output.tmp_matrix} {output.depthmatrix}
            fi
        done < {input.depthfilelist}
        '''

rule mask_low_coverage:
    input:
        vcf=config['out']['outdir']+"/{sampleSet}_{regionSet}_merged_germline_variants_SNP_depth.vcf.gz",
        depthmatrix=config['out']['outdir']+"/{sampleSet}_{regionSet}_germline_depth_matrix_for_phylo.txt"
    output:
        maksed_vcf=config['out']['outdir']+"/{sampleSet}_{regionSet}_merged_germline_variants_SNP_masked.vcf.gz",
        maksed_idx=config['out']['outdir']+"/{sampleSet}_{regionSet}_merged_germline_variants_SNP_masked.vcf.gz.csi"
    params:
        mask_vcf=config['scripts']['mask_vcf'],
        minCoverage=10
    threads:
        config['resources']['threads']
    resources:
        mem=config['resources']['mem']
    conda:
        config['envs']['phylogenetics']
    shell:
        '''
        python {params.mask_vcf} \
            {input.depthmatrix} \
            {input.vcf} \
            {output.maksed_vcf} \
            {params.minCoverage} \
            {threads} \
            {resources.mem}
        bcftools index {output.maksed_vcf}
        '''

rule prepare_somatic_sites:
    input:
        config['in']['somaticMutation']
    output:
        config['out']['outdir']+"/somaticMutation_sites.tab"
    shell:
        '''
        awk 'BEGIN{{OFS="\\t"}} {{if ($1 !~ /chrom/) {{print $1,$2;}} }}' \
            {input} > {output}
        '''

rule remove_somatic:
    input:
        maksed_vcf=config['out']['outdir']+"/{sampleSet}_{regionSet}_merged_germline_variants_SNP_masked.vcf.gz",
        maksed_idx=config['out']['outdir']+"/{sampleSet}_{regionSet}_merged_germline_variants_SNP_masked.vcf.gz.csi",
        somatic=config['out']['outdir']+"/somaticMutation_sites.tab"
    output:
        cleaned_vcf=config['out']['outdir']+"/{sampleSet}_{regionSet}_merged_germline_variants_SNP_masked_cleaned.vcf.gz"
    threads:
        1
    conda:
        config['envs']['phylogenetics']
    shell:
        '''
        bcftools view --threads {threads} -O z \
            -T ^{input.somatic} \
            -o {output.cleaned_vcf} \
            {input.maksed_vcf}
        '''

rule distance_matrix:
    input:
        vcf=config['out']['outdir']+"/{sampleSet}_{regionSet}_merged_germline_variants_SNP_masked_cleaned.vcf.gz"
    output:
        matrix=config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}_merged_germline_variants_SNP.mdist.gz",
        distid=config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}_merged_germline_variants_SNP.mdist.id"
    threads:
        config['resources']['threads']
    resources:
        mem=config['resources']['mem']
    conda:
        config['envs']['phylogenetics']
    shell:
        '''
        mem_mb=`echo {resources.mem} | sed 's/G/000/g'`
        prefix=`echo {output.matrix} | sed 's/.mdist.gz//g'`
        plink --threads {threads} --memory ${{mem_mb}} --seed 123 --dog \
            --distance gz square '1-ibs' \
            --vcf {input.vcf} \
            --out ${{prefix}}
        '''

rule mdist2phydist:
    input:
        matrix=config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}_merged_germline_variants_SNP.mdist.gz",
        distid=config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}_merged_germline_variants_SNP.mdist.id",
        script=config['project_dir']+"/scripts/phylogenetic/mdist2phydist.py"
    output:
        phydist=config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}_merged_germline_variants_SNP.phylip"
    conda:
        config['envs']['phylogenetics']
    shell:
        '''
        python {input.script} \
            --mdist {input.matrix} \
            --id {input.distid} \
            --phydist {output.phydist} 
        '''

rule phylip_neighbor:
    input:
        phydist=config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}_merged_germline_variants_SNP.phylip"
    output:
        tree=config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}.nwk",
        command=temp(config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}.nwk.command")
    log:
        config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}.log"
    params:
        outdir=config['out']['outdir']+"/{sampleSet}_{regionSet}",
        outfile=config['out']['outdir']+"/{sampleSet}_{regionSet}/outfile",
        outtree=config['out']['outdir']+"/{sampleSet}_{regionSet}/outtree"
    conda:
        config['envs']['phylogenetics']
    shell:
        '''
        cd {params.outdir}
        echo "{input.phydist}" > {output.command}
        echo "Y" >> {output.command}
        rm -f {params.outfile} {params.outtree}
        neighbor < {output.command} > {log}
        mv {params.outtree} {output.tree}
        cat {params.outfile} >> {log}
        rm {params.outfile}
        '''

# rule phylip_consense:


rule phylip_nwk_vis:
    input:
        tree=config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}.nwk",
        distid=config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}_merged_germline_variants_SNP.mdist.id",
        metatable=config['in']['metatable'],
        script=config['project_dir']+"/scripts/phylogenetic/phylip_nwk_vis.R"
    output:
        figure=config['out']['outdir']+"/{sampleSet}_{regionSet}/{sampleSet}_{regionSet}.pdf"
    conda:
        config['envs']['phylogenetics']
    shell:
        '''
        Rscript --vanilla {input.script} \
            {wildcards.sampleSet}_{wildcards.regionSet} \
            {input.tree} \
            {input.distid} \
            {input.metatable} \
            {output.figure}
        '''